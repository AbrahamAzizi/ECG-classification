{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SZ6VDsiOlYMq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Fix random seed\n",
        "np.random.seed(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biosppy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oFtACZ93eJd",
        "outputId": "859a5c15-35e7-413d-d1d5-6f04046147bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biosppy\n",
            "  Downloading biosppy-2.1.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/142.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m133.1/142.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bidict in /usr/local/lib/python3.10/dist-packages (from biosppy) (0.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.11.4)\n",
            "Collecting shortuuid (from biosppy)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from biosppy) (4.8.0.76)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->biosppy) (3.3.0)\n",
            "Installing collected packages: shortuuid, biosppy\n",
            "Successfully installed biosppy-2.1.2 shortuuid-1.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrtBwXcIy13d",
        "outputId": "e07d58c1-7922-4a13-c2ec-1f16061045af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AML/Task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EB1x_Ak3UDs",
        "outputId": "9ea62d3f-70b2-4106-8d75-2c8fab454114"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AML/Task2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVy1-6ov6aoN"
      },
      "source": [
        "**Install BioSPPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBHTJ_6ilLCK"
      },
      "source": [
        "**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IJv9M04FmDOp"
      },
      "outputs": [],
      "source": [
        "df_x_train = pd.read_csv('X_train.csv')\n",
        "df_y_train = pd.read_csv('y_train.csv')\n",
        "df_x_test = pd.read_csv('X_test.csv')\n",
        "df_sample = pd.read_csv('sample.csv')\n",
        "\n",
        "# drop the column id\n",
        "df_x_train = df_x_train.drop('id', axis=1)\n",
        "df_y_train = df_y_train.drop('id', axis=1)\n",
        "df_x_test = df_x_test.drop('id', axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yxzy2uTGsZHi"
      },
      "outputs": [],
      "source": [
        "# to numpy\n",
        "x_train_total = df_x_train.to_numpy(dtype='float32')\n",
        "y_train_total = df_y_train.to_numpy()\n",
        "x_test = df_x_test.to_numpy(dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4CQP5xbu-tu"
      },
      "source": [
        "**Feature extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wyKrAEz5HvlV"
      },
      "outputs": [],
      "source": [
        "import biosppy.signals.ecg as ecg\n",
        "\n",
        "# hyper parameter:\n",
        "th = 0.48 #r-peak segmentation\n",
        "\n",
        "def extract_features(X):\n",
        "  X_features = np.array([])\n",
        "  n_features = 34\n",
        "  for row in X:\n",
        "    # row without Nans\n",
        "    row = row[np.logical_not(np.isnan(row))]\n",
        "    # R-peak location indices\n",
        "    r_peaks = ecg.engzee_segmenter(row, sampling_rate=300, threshold=th)['rpeaks']\n",
        "    if r_peaks.shape == (0,): #TODO: what to do with those samples?\n",
        "      features = np.zeros(n_features) #set all features to zero if no R-peak was found\n",
        "      print(\"No R-peak found in sample: \", X_features.shape[0])\n",
        "    else:\n",
        "      # heartbeat templates\n",
        "      beats = ecg.extract_heartbeats(row, r_peaks, sampling_rate=300, before=0.2, after=0.4)['templates']\n",
        "      beats_var_mean = np.mean(np.std(beats, axis=0))\n",
        "      beats_var_md = np.median(np.std(beats, axis=0))\n",
        "      beats_var_var = np.std(np.std(beats, axis=0))\n",
        "\n",
        "      amplitude_mean = np.mean(np.mean(np.power(beats, 2), axis=1)) #squared\n",
        "      amplitude_md = np.median(np.mean(np.power(beats, 2), axis=1)) #squared\n",
        "      amplitude_var = np.std(np.mean(np.power(beats, 2), axis=1)) #squared\n",
        "\n",
        "      # R-peak: always at T=60\n",
        "      r_mean = np.mean(beats[:, 60])\n",
        "      r_md = np.median(beats[:, 60])\n",
        "      r_var = np.std(beats[:, 60])\n",
        "\n",
        "      # P-peak: smaller peak before R-peak, 40 good?\n",
        "      p_mean = np.mean(np.amax(beats[:, :40], axis=1))\n",
        "      p_md = np.median(np.amax(beats[:, :40], axis=1))\n",
        "      p_var = np.std(np.amax(beats[:, :40], axis=1))\n",
        "      p_position = np.mean(np.argmax(beats[:, :40], axis=1))\n",
        "      p_position_var = np.std(np.argmax(beats[:, :40], axis=1))\n",
        "      if p_position == 40.0:\n",
        "        print(\"P peak earlier\") #TODO: position good?\n",
        "\n",
        "      # Q-drop: before R-peak\n",
        "      q_mean = np.mean(np.amin(beats[:, :60], axis=1))\n",
        "      q_md = np.median(np.amin(beats[:, :60], axis=1))\n",
        "      q_var = np.std(np.amin(beats[:, :60], axis=1))\n",
        "      q_position = np.mean(np.argmin(beats[:, :60], axis=1))\n",
        "      q_position_var = np.std(np.argmin(beats[:, :60], axis=1))\n",
        "\n",
        "      # S-drop: after R-peak\n",
        "      s_mean = np.mean(np.amin(beats[:, 60:], axis=1))\n",
        "      s_md = np.median(np.amin(beats[:, 60:], axis=1))\n",
        "      s_var = np.std(np.amin(beats[:, 60:], axis=1))\n",
        "      s_position = np.mean(np.argmin(beats[:, 60:], axis=1))\n",
        "      s_position_var = np.std(np.argmin(beats[:, 60:], axis=1))\n",
        "\n",
        "      # T-peak: after R-peak, 80 good?\n",
        "      t_mean = np.mean(np.amax(beats[:, 80:], axis=1))\n",
        "      t_md = np.median(np.amax(beats[:, 80:], axis=1))\n",
        "      t_var = np.std(np.amax(beats[:, 80:], axis=1))\n",
        "      t_position = np.mean(np.argmax(beats[:, 80:], axis=1))\n",
        "      t_position_var = np.std(np.argmax(beats[:, 80:], axis=1))\n",
        "      if t_position == 0.0:\n",
        "        print(\"T peak later\") #TODO: position good?\n",
        "\n",
        "      # instantaneous heart rate (bpm)\n",
        "      heart_rate = ecg.ecg(row, 300, show=False)['heart_rate']\n",
        "      if heart_rate.shape == (0,):\n",
        "        hr_mean = 0\n",
        "        hr_md = 0\n",
        "        hr_var = 0\n",
        "        hr_max = 0\n",
        "        hr_min = 0\n",
        "      else:\n",
        "        hr_mean = np.mean(heart_rate)\n",
        "        hr_md = np.median(heart_rate)\n",
        "        hr_var = np.std(heart_rate)\n",
        "        hr_max = np.amax(heart_rate)\n",
        "        hr_min = np.amin(heart_rate)\n",
        "\n",
        "      features = np.array([beats_var_mean, beats_var_md, beats_var_var,\n",
        "                  amplitude_mean, amplitude_md, amplitude_var,\n",
        "                  r_mean, r_md, r_var,\n",
        "                  p_mean, p_md, p_var, p_position, p_position_var,\n",
        "                  q_mean, q_md, q_var, q_position, q_position_var,\n",
        "                  s_mean, s_md, s_var, s_position, s_position_var,\n",
        "                  t_mean, t_md, t_var, t_position, t_position_var,\n",
        "                  hr_mean, hr_md, hr_var, hr_max, hr_min])\n",
        "\n",
        "    if X_features.shape == (0,):\n",
        "      X_features = features\n",
        "    else:\n",
        "      X_features = np.vstack((X_features, features))\n",
        "\n",
        "  # Normalize\n",
        "  X_features = np.array(X_features)\n",
        "  m = np.nanmean(X_features, axis=0)\n",
        "  s = np.nanstd(X_features, axis=0)\n",
        "  X_features = X_features - m\n",
        "  X_features = X_features / s\n",
        "\n",
        "  return X_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "58E0SPLbMdzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41238de8-c97c-408a-e250-454c817a7549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T peak later\n",
            "T peak later\n",
            "No R-peak found in sample:  447\n",
            "No R-peak found in sample:  579\n",
            "No R-peak found in sample:  593\n",
            "No R-peak found in sample:  955\n",
            "No R-peak found in sample:  1135\n",
            "T peak later\n",
            "No R-peak found in sample:  1247\n",
            "No R-peak found in sample:  1383\n",
            "No R-peak found in sample:  2931\n",
            "No R-peak found in sample:  3009\n",
            "T peak later\n",
            "No R-peak found in sample:  3145\n",
            "T peak later\n",
            "T peak later\n",
            "No R-peak found in sample:  3519\n",
            "T peak later\n",
            "No R-peak found in sample:  3884\n",
            "No R-peak found in sample:  4025\n",
            "T peak later\n",
            "T peak later\n",
            "No R-peak found in sample:  4340\n",
            "T peak later\n",
            "No R-peak found in sample:  4625\n",
            "No R-peak found in sample:  4684\n",
            "No R-peak found in sample:  4688\n",
            "No R-peak found in sample:  4693\n",
            "No R-peak found in sample:  4871\n"
          ]
        }
      ],
      "source": [
        "x_train_total_features = extract_features(x_train_total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4lyOX_HNGTK"
      },
      "source": [
        "# **Cross-Validate**\n",
        "## Instead of model one can use any classifier. Moreover, the best can be stacked many xgboost(more than 10), random forest, and ridge regression as the final classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zA7h1uOQaBCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f566362-be8a-4e27-d3b9-4543a576f79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split  1  of  10\n",
            "F1 score of training set:  0.9488615497612927\n",
            "F1 score of validation set:  0.732421875\n",
            "Split  2  of  10\n",
            "F1 score of training set:  0.9555209097578871\n",
            "F1 score of validation set:  0.720703125\n",
            "Split  3  of  10\n",
            "F1 score of training set:  0.9496521420725009\n",
            "F1 score of validation set:  0.71484375\n",
            "Split  4  of  10\n",
            "F1 score of training set:  0.9548969072164949\n",
            "F1 score of validation set:  0.6953125\n",
            "Split  5  of  10\n",
            "F1 score of training set:  0.946107234667646\n",
            "F1 score of validation set:  0.701171875\n",
            "Split  6  of  10\n",
            "F1 score of training set:  0.9474071349760942\n",
            "F1 score of validation set:  0.728515625\n",
            "Split  7  of  10\n",
            "F1 score of training set:  0.9490353112486348\n",
            "F1 score of validation set:  0.708984375\n",
            "Split  8  of  10\n",
            "F1 score of training set:  0.9456401766004415\n",
            "F1 score of validation set:  0.7142857142857143\n",
            "Split  9  of  10\n",
            "F1 score of training set:  0.9503474762253109\n",
            "F1 score of validation set:  0.6731898238747553\n",
            "Split  10  of  10\n",
            "F1 score of training set:  0.9495060373216246\n",
            "F1 score of validation set:  0.7084148727984344\n",
            "CV score:  0.7097843535958904\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import resample\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "s=0\n",
        "n_splits = 10\n",
        "val_score_sum = 0\n",
        "kf = KFold(n_splits=n_splits)\n",
        "for train_index, test_index in kf.split(x_train_total_features):\n",
        "  x_train, x_val = x_train_total_features[train_index], x_train_total_features[test_index]\n",
        "  y_train, y_val = y_train_total[train_index], y_train_total[test_index]\n",
        "  s += 1\n",
        "  print(\"Split \", s, \" of \", n_splits)\n",
        "\n",
        "\n",
        "  # Class Imbalance\n",
        "\n",
        "  train = np.concatenate((y_train, x_train), axis=1)\n",
        "  y_train = y_train.ravel() #reshape\n",
        "  train_0 = train[y_train == 0]\n",
        "  train_1 = train[y_train == 1]\n",
        "  train_2 = train[y_train == 2]\n",
        "  train_3 = train[y_train == 3]\n",
        "\n",
        "\n",
        "  # upsample minority classes (Class 0 is the biggest class)\n",
        "  train_1_upsampled = resample(train_1,\n",
        "                            replace=True, # sample with replacement\n",
        "                            n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "  train_2_upsampled = resample(train_2,\n",
        "                            replace=True, # sample with replacement\n",
        "                            n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "  train_3_upsampled = resample(train_3,\n",
        "                            replace=True, # sample with replacement\n",
        "                            n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "  train_upsampled = np.concatenate((train_0, train_1_upsampled, train_2_upsampled, train_3_upsampled), axis=0)\n",
        "\n",
        "  y_train_upsampled, x_train_upsampled = np.split(train_upsampled, [1], axis=1)\n",
        "\n",
        "  y_train_upsampled = y_train_upsampled.ravel() #reshape\n",
        "\n",
        "  # Classification Model\n",
        "\n",
        "  model = svm.SVC(C=100.0, class_weight='balanced', probability=True, tol=1e-6)\n",
        "\n",
        "  model.fit(x_train_upsampled, y_train_upsampled)\n",
        "\n",
        "\n",
        "  # Evaluation\n",
        "\n",
        "  #training set\n",
        "  y_train_pred = model.predict(x_train_upsampled)\n",
        "  F1 = f1_score(y_train_upsampled, y_train_pred, average='micro')\n",
        "  print('F1 score of training set: ', F1)\n",
        "\n",
        "  #validation set\n",
        "  y_val_pred = model.predict(x_val)\n",
        "  F1 = f1_score(y_val, y_val_pred, average='micro')\n",
        "  print('F1 score of validation set: ', F1)\n",
        "  val_score_sum += F1\n",
        "\n",
        "val_score_mean = val_score_sum/n_splits\n",
        "print(\"CV score: \", val_score_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt8_trqzvPmT"
      },
      "source": [
        "**Fit and predict on whole training set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "juXpvgzLCujB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5c928d-36c9-4ecc-d325-fca3d5549dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No R-peak found in sample:  155\n",
            "No R-peak found in sample:  172\n",
            "No R-peak found in sample:  450\n",
            "No R-peak found in sample:  509\n",
            "No R-peak found in sample:  646\n",
            "No R-peak found in sample:  704\n",
            "T peak later\n",
            "No R-peak found in sample:  950\n",
            "No R-peak found in sample:  970\n",
            "No R-peak found in sample:  1040\n",
            "No R-peak found in sample:  1147\n",
            "T peak later\n",
            "T peak later\n",
            "No R-peak found in sample:  1740\n",
            "No R-peak found in sample:  2223\n",
            "No R-peak found in sample:  2267\n",
            "No R-peak found in sample:  2304\n",
            "No R-peak found in sample:  2501\n",
            "No R-peak found in sample:  3169\n",
            "No R-peak found in sample:  3381\n",
            "T peak later\n"
          ]
        }
      ],
      "source": [
        "x_test_features = extract_features(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBK5kQCNcykP"
      },
      "source": [
        "**Class Imbalance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "coJVOjxRcxEm"
      },
      "outputs": [],
      "source": [
        "train = np.concatenate((y_train_total, x_train_total_features), axis=1)\n",
        "y_train_total = y_train_total.reshape(y_train_total.shape[0])\n",
        "train_0 = train[y_train_total == 0]\n",
        "train_1 = train[y_train_total == 1]\n",
        "train_2 = train[y_train_total == 2]\n",
        "train_3 = train[y_train_total == 3]\n",
        "\n",
        "\n",
        "# upsample minority classes (Class 0 is the biggest class)\n",
        "train_1_upsampled = resample(train_1,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "train_2_upsampled = resample(train_2,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "train_3_upsampled = resample(train_3,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(train_0)) # match number in majority class\n",
        "\n",
        "train_upsampled = np.concatenate((train_0, train_1_upsampled, train_2_upsampled, train_3_upsampled), axis=0)\n",
        "\n",
        "y_train_upsampled, x_train_upsampled = np.split(train_upsampled, [1], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Chjc4vpdxElt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebc1ee6-d8f2-4ca9-de4f-94f3693f0ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_upsampled, y_train_upsampled)\n",
        "y_pred = model.predict(x_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMfygyekNYb-",
        "outputId": "85271c12-c731-4b5f-bf66-2b4be96de241"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3411,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ2JoVBrw70i"
      },
      "source": [
        "**Save to file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9DA8Ti3Bw-Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6572d9-d2f2-4d18-8795-ad3e985da403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0\n",
            "0  0.0\n",
            "1  2.0\n",
            "2  3.0\n",
            "3  0.0\n",
            "4  2.0\n"
          ]
        }
      ],
      "source": [
        "df_sample = pd.DataFrame(y_pred,)\n",
        "print(df_sample.head())\n",
        "df_sample.to_csv('pred.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Task2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}